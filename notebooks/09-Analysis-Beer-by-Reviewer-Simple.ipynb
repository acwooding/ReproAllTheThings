{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quick cell to make jupyter notebook use the full screen width\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some plotting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "from bokeh.plotting import show, save, output_notebook, output_file\n",
    "from bokeh.resources import INLINE \n",
    "output_notebook(resources=INLINE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import workflow\n",
    "from src.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "import umap.plot\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beer_ds = Dataset.load(\"beer_by_reviewers_simple\")\n",
    "beer = beer_ds.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embed the data\n",
    "\n",
    "We are going to vectorize our data and look at the number of categorical values they have in common.  A useful thing to do here is to require each row to have a minimum support before being included.  Filtering this early, will ensure indices line up later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_beer = beer[beer.review_profilename_len>20].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_beer.head().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step turns a sequence of space seperated text into a sparse matrix of counts.  One row per row of our data frame and one column per unique token that appeared in our categorical field of interest.\n",
    "\n",
    "If we want to deal with sets (i.e. just presence or absence of a category) use:<BR>\n",
    "`beer_by_authors_vectorizer = CountVectorizer(binary=True)`<BR>\n",
    "If we think counts should matter we might use:<BR>\n",
    "`beer_by_authors_vectorizer = CountVectorizer()`<BR>\n",
    "or if we want to correct for very unbalanced column frequencies:<BR>\n",
    "`beer_by_authors_vectorizer = TfidfVectorizer()`<BR>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beer_by_authors_vectorizer = CountVectorizer(binary=True, min_df=20)\n",
    "beer_by_authors = beer_by_authors_vectorizer.fit_transform(popular_beer.review_profilename_list)\n",
    "beer_by_authors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we reduce the dimension of this data.\n",
    "\n",
    "If we are dealing with sets (i.e. just presence or absence of a category) use:<BR>\n",
    "`metric='jaccard'`<BR>\n",
    "If we think counts should matter we might use:<BR>\n",
    "`metric='hellinger'`<BR>\n",
    "or if we want to correct for very unbalanced column frequencies:<BR>\n",
    "tfidfVectorizor followed by `metric='hellinger'`<BR>\n",
    "    \n",
    "As you get more and more points I'd recommend increasing the `n_neighbors` parameter to compensate.  Thing of this as a resolution parameter.\n",
    "\n",
    "`n_components` controls the dimension you will be embedding your data into (2-dimensions for easy visualization).  Feel free to embed into higher dimensions for clustering if you'd like.\n",
    "\n",
    "`unique=True` says that if you have two identical points you want to map them to the exact same co-ordinates in your low space.  This becomes especially important if you have more exact dupes that your `n_neighbors` parameter.  That is the problem case where exact dupes can be pushed into very different regions of your space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "beer_by_authors_model = umap.UMAP(n_neighbors=15, n_components=2, metric='jaccard', min_dist=0.3,\n",
    "                                  unique=True, random_state=42).fit(beer_by_authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile ='results/popular_beer_by_reviewer_jaccard'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abv_label = popular_beer.beer_abv.fillna(0)\n",
    "umap_plot = umap.plot.points(beer_by_authors_model, labels=popular_beer.brewery_name, theme='fire');\n",
    "#umap_plot.figure.savefig(outfile+'.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and now for an interactive plot with mouseover."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abv_label = popular_beer.beer_abv.fillna(0)\n",
    "hover_df = popular_beer['beer_beerid beer_name brewery_name beer_style'.split()]\n",
    "f = umap.plot.interactive(beer_by_authors_model, labels=popular_beer.brewery_name, hover_data=hover_df, theme='fire', point_size=5);\n",
    "#save(f,outfile+'.html')\n",
    "show(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that there is a fairly strong tendency to group beers from the same breweries together.  It makes some sense that reviewers tend to sample all the beers from a given brewery (especially if they like the brewery).  \n",
    "\n",
    "Smaller niche breweries get pulled out of the main cluster as they are reviewed by a small set of individuals who haven't reviewed much else.  Thus they are strongly connected to each other and not to the main cloud."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What if we wanted to only group beer by the users that liked them?\n",
    "\n",
    "Are two beers similar if two reviewer tried them?  Perhaps not, instead lets filter to only the reviewers who enjoyed the beer.\n",
    "\n",
    "Because this is talking about reviewers and not beer we need to filter our initial data frame and re-run our process.\n",
    "\n",
    "Let's try that next: [10-Data-Beer-by-Reviewer-Positive](10-Data-Beer-by-Reviewer-Positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:reproallthethings] *",
   "language": "python",
   "name": "conda-env-reproallthethings-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
