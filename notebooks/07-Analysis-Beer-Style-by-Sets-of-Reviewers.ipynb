{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quick cell to make jupyter notebook use the full screen width\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some plotting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "from bokeh.plotting import show, save, output_notebook, output_file\n",
    "from bokeh.resources import INLINE \n",
    "output_notebook(resources=INLINE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import workflow\n",
    "from src.data import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First step of the embedding: CountVectorize\n",
    "\n",
    "We are going to vectorize our data and look at the number of categorical values they have in common.  A useful thing to do here is to require each row to have a minimum support before being included.  Filtering this early, will ensure indices line up later on.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beer_style_dset = Dataset.load(\"beer_style_reviewers\")\n",
    "beer_style_dset.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beer_style = beer_style_dset.data\n",
    "beer_style.review_profilename_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This step turns a sequence of space seperated text into a sparse matrix of counts.  One row per row of our data frame and one column per unique token that appeared in our categorical field of interest.\n",
    "\n",
    "If we want to deal with sets (i.e. just presence or absence of a category) use:<BR>\n",
    "`beer_by_authors_vectorizer = CountVectorizer(binary=True)`<BR>\n",
    "If we think counts should matter we might use:<BR>\n",
    "`beer_by_authors_vectorizer = CountVectorizer()`<BR>\n",
    "or if we want to correct for very unbalanced column frequencies:<BR>\n",
    "`beer_by_authors_vectorizer = TfidfVectorizer()`<BR>\n",
    "    \n",
    "We use `min_df=10` in our CountVectorize to only count reviewers who have reviewed at least 10 beers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "style_by_authors_vectorizer = CountVectorizer(binary=True, min_df=10)\n",
    "style_by_authors = style_by_authors_vectorizer.fit_transform(beer_style.review_profilename_list)\n",
    "style_by_authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:reproallthethings] *",
   "language": "python",
   "name": "conda-env-reproallthethings-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
