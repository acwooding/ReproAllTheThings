{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quick cell to make jupyter notebook use the full screen width\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some plotting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "from bokeh.plotting import show, save, output_notebook, output_file\n",
    "from bokeh.resources import INLINE \n",
    "output_notebook(resources=INLINE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import workflow\n",
    "from src.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "import umap.plot\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beer_ds = Dataset.load(\"beer_by_reviewers\")\n",
    "beer = beer_ds.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embed the data\n",
    "\n",
    "We are going to vectorize our data and look at the number of categorical values they have in common.  A useful thing to do here is to require each row to have a minimum support before being included.  Filtering this early, will ensure indices line up later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_beer = beer[beer.review_profilename_len>50].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step turns a sequence of space seperated text into a sparse matrix of counts.  One row per row of our data frame and one column per unique token that appeared in our categorical field of interest.\n",
    "\n",
    "If we want to deal with sets (i.e. just presence or absence of a category) use:<BR>\n",
    "`beer_by_authors_vectorizer = CountVectorizer(binary=True)`<BR>\n",
    "If we think counts should matter we might use:<BR>\n",
    "`beer_by_authors_vectorizer = CountVectorizer()`<BR>\n",
    "or if we want to correct for very unbalanced column frequencies:<BR>\n",
    "`beer_by_authors_vectorizer = TfidfVectorizer()`<BR>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beer_by_authors_vectorizer = CountVectorizer(binary=True, min_df=10)\n",
    "beer_by_authors = beer_by_authors_vectorizer.fit_transform(popular_beer.review_profilename_list)\n",
    "beer_by_authors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we reduce the dimension of this data.\n",
    "\n",
    "If we are dealing with sets (i.e. just presence or absence of a category) use:<BR>\n",
    "`metric='jaccard'`<BR>\n",
    "If we think counts should matter we might use:<BR>\n",
    "`metric='hellinger'`<BR>\n",
    "or if we want to correct for very unbalanced column frequencies:<BR>\n",
    "`metric='hellinger'`<BR>\n",
    "    \n",
    "As you get more and more points I'd recommend increasing the `n_neighbors` parameter to compensate.  Thing of this as a resolution parameter.\n",
    "\n",
    "`n_components` controls the dimension you will be embedding your data into (2-dimensions for easy visualization).  Feel free to embed into higher dimensions for clustering if you'd like.\n",
    "\n",
    "`unique=True` says that if you have two identical points you want to map them to the exact same co-ordinates in your low space.  This becomes especially important if you have more exact dupes that your `n_neighbors` parameter.  That is the problem case where exact dupes can be pushed into very different regions of your space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "beer_by_authors_model = umap.UMAP(n_neighbors=15, n_components=2, metric='jaccard', unique=True, random_state=42).fit(beer_by_authors.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_plot = umap.plot.points(beer_by_authors_model, labels=popular_beer.brewery_name, theme='fire');\n",
    "#umap_plot.figure.savefig('results/popular_beer_by_positive_reviewer_jaccard.png', dpi=300, bbox_inches='tight', transparent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and now for an interactive plot with mouseover."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abv_label = popular_beer.beer_abv.fillna(0)\n",
    "hover_df = popular_beer['beer_beerid beer_name brewery_name beer_style'.split()]\n",
    "f = umap.plot.interactive(beer_by_authors_model, labels=popular_beer.brewery_name, hover_data=hover_df, theme='fire', point_size=5);\n",
    "#save(f,'results/popular_beer_by_positive_reviewers_jaccard.html')\n",
    "show(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:reproallthethings] *",
   "language": "python",
   "name": "conda-env-reproallthethings-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
