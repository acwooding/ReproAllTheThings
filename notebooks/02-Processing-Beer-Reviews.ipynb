{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quick cell to make jupyter notebook use the full screen wi\"dth\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic utility functions\n",
    "import logging\n",
    "from src.logging import logger\n",
    "from src.paths import Paths\n",
    "from src.utils import list_dir\n",
    "paths = Paths()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grab the Beer Review DataSource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import DataSource\n",
    "from src import workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.available_datasources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsrc = DataSource.from_name('beer_review')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsrc.file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsrc.unpack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now following https://github.com/acwooding/cookiecutter-easydata/blob/bus_number/%7B%7B%20cookiecutter.repo_name%20%7D%7D/notebooks/22-transform-datasources-to-datasets.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -la $paths.interim_data_path/beer_review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check that our data looks like that of JH and the Kaggle site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head $paths.interim_data_path/beer_review/beer_reviews.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a process function\n",
    "\n",
    "This is a nice dataset. Note really any clean up to do here. Just fixing things up to match the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pathlib\n",
    "\n",
    "def process_beer_review(*, unpack_dir, kind='all', extract_dir='beer_review',\n",
    "                        unpack=False, raw_dir=None, metadata=None):\n",
    "    \"\"\"\n",
    "    Process beer reviews into (data, target, metadata) format. Since we plan to use Pandas\n",
    "    for further processing, data will be a pandas dataframe. As Pandas will read that too.\n",
    "    \n",
    "    In this case, if we \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    unpack_dir:\n",
    "        The directory the reviews have been unpacked into\n",
    "    raw_dir:\n",
    "        The directory the raw zip file\n",
    "    kind: {'all'}\n",
    "        This is an unsupervised learning example. There are no labels. We will only work\n",
    "        with the whole dataset. (Optionally add train and test set later for experimenting.)\n",
    "    extract_dir: \n",
    "        Name of the directory of the unpacked zip file containing the raw data files.\n",
    "    unpack: boolean\n",
    "        If unpack is False, process data without bothering to unpack it. Requires raw_dir.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A tuple:\n",
    "        (data, target, additional_metadata)\n",
    "        \n",
    "    \"\"\"\n",
    "    if metadata is None:\n",
    "        metadata = {}\n",
    "    \n",
    "    if unpack:\n",
    "        if unpack_dir:\n",
    "            unpack_dir = pathlib.Path(unpack_dir)\n",
    "            data_dir = unpack_dir / extract_dir\n",
    "            data = pd.read_csv(data_dir/\"beer_reviews.csv\")\n",
    "    else:\n",
    "        if raw_dir:\n",
    "            raw_dir = pathlib.Path(raw_dir)\n",
    "            data = pd.read_csv(raw_dir/\"beerreviews.zip\")\n",
    "        else:\n",
    "            raise ValueError(\"raw_dir required\")\n",
    "    \n",
    "    target = None\n",
    "    \n",
    "    return data, target, metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsrc.file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsrc.default_metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, target, metadata = process_beer_review(unpack_dir=paths.interim_data_path, unpack=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interesting Tidbits:\n",
    "\n",
    "25% of the beer_beerid have no recorded beer_abv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good. Now add this as a parse function for our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "dsrc.parse_function = partial(process_beer_review, unpack_dir=str(paths.interim_data_path),\n",
    "                              unpack=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsrc.dataset_opts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ds = dsrc.process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now that things seem to work, we need to move the process function to the src module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# low on space and need to move things off of my main disk.\n",
    "!cd .. && make clean_raw && make clean_interim && make clean_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file ../src/data/localdata.py\n",
    "\"\"\"\n",
    "Custom dataset processing/generation functions should be added to this file\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "\n",
    "__all__ = [\n",
    "    'process_beer_review'\n",
    "]\n",
    "\n",
    "\n",
    "def process_beer_review(*, unpack_dir, kind='all', extract_dir='beer_review',\n",
    "                        unpack=False, raw_dir=None, metadata=None):\n",
    "    \"\"\"\n",
    "    Process beer reviews into (data, target, metadata) format. Since we plan to use Pandas\n",
    "    for further processing, data will be a pandas dataframe. As Pandas will read that too.\n",
    "    \n",
    "    In this case, if we \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    unpack_dir:\n",
    "        The directory the reviews have been unpacked into\n",
    "    raw_dir:\n",
    "        The directory the raw zip file\n",
    "    kind: {'all'}\n",
    "        This is an unsupervised learning example. There are no labels. We will only work\n",
    "        with the whole dataset. (Optionally add train and test set later for experimenting.)\n",
    "    extract_dir: \n",
    "        Name of the directory of the unpacked zip file containing the raw data files.\n",
    "    unpack: boolean\n",
    "        If unpack is False, process data without bothering to unpack it. Requires raw_dir.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A tuple:\n",
    "        (data, target, additional_metadata)\n",
    "        \n",
    "    \"\"\"\n",
    "    if metadata is None:\n",
    "        metadata = {}\n",
    "    \n",
    "    if unpack:\n",
    "        if unpack_dir:\n",
    "            unpack_dir = pathlib.Path(unpack_dir)\n",
    "            data_dir = unpack_dir / extract_dir\n",
    "            data = pd.read_csv(data_dir/\"beer_reviews.csv\")\n",
    "    else:\n",
    "        if raw_dir:\n",
    "            raw_dir = pathlib.Path(raw_dir)\n",
    "            data = pd.read_csv(raw_dir/\"beerreviews.zip\")\n",
    "        else:\n",
    "            raise ValueError(\"raw_dir required\")\n",
    "    \n",
    "    target = None\n",
    "    \n",
    "    return data, target, metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.localdata import process_beer_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsrc.parse_function = partial(process_beer_review, unpack_dir=str(paths.interim_data_path),\n",
    "                              raw_dir=str(paths.raw_data_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsrc.fetch(force=True)\n",
    "dsrc.unpack(force=True)\n",
    "ds = dsrc.process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.add_datasource(dsrc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.available_datasources(keys_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time to check things in. Then mount data to something with more storage!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make is broken. Now that I've mounted things..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsrc = DataSource.from_name('beer_review')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsrc.fetch()\n",
    "dsrc.unpack()\n",
    "ds = dsrc.process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.available_datasources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.available_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.available_datasources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use a dummy transformer to get to the dataset we want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.add_transformer(from_datasource='beer_review',\n",
    "                        output_dataset='beer_review_all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.make_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.available_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:reproallthethings] *",
   "language": "python",
   "name": "conda-env-reproallthethings-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
